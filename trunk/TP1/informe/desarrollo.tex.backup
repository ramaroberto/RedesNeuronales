\documentclass[informe.tex]{subfiles}
\begin{document}
  
  \section{Desarrollo}

  A fin de lograr que todas las características observadas tengan la misma influencia en la red (y evitar que por ejemplo la la influencia de una característica con amplitud y valor absoluto en sus valores sea mayor que la de una con análogos menores) analizamos los resultados al hacer un preprocesamiento de cada paracterística en las bases de datos.
  
  Como preprocesamiento elegimos realizar una normalización de cada característica numérica, incluyendo la salida en el segundo conjunto de datos. Para el caso de la salida en el primer conjunto que consiste en 
  
  
  
  
  
    \subsection{Generación de instancias de prueba}
    
      Con el objetivo de evaluar diferentes arquitecturas de redes decidimos particionar el conjunto de datos disponibles (realizando la misma operación para cada dataset) utilizando k-fold cross-validation para disminuir los efectos de tomar conjuntos poco representativos y analizar el funcionamiento de una determinada selección de parámetros sobre distintas particiones de los datos. Sin embargo, considerando que debemos realizar una serie de pruebas en un tiempo acotado, decidimos acotarlas de la siguiente manera.
      
      Particionamos la totalidad de los datos en cuatro partes, cada una considerando el 25\% de los mismos. Dada esa partición generamos 4 folds diferentes. Así, entrenamos con el 75\% y testeamos en el 25\% restante con cada una de las variantes.
      
    \subsection{Variantes consideradas}
    
      El desarrollo del trabajo consisti\'o fundamentalmente en analizar distintas variantes para la red a fin de obtener par\'ametros que permitiesen obtener buenos resultados en cada problema. Para ello, cada uno de los mismos fue tratado de manera independiente y se realizaron distintas pruebas que se detallan a continuaci\'on.
    
      \subsubsection{Arquitectura adecuada al problema}
	Uno de los aspectos fundamentales sobre el funcionamiento de una red neuronal es su configuraci\'on respecto de la cantidad de capas y de neuronas en cada una de ellas. Durante el desarrollo consideramos distintas configuraciones, comenzando con una \'unica capa oculta y variando la cantidad de neuronas en ella. Para esto consideramos la heurística de considerar cantidad de neuronas entre la cantidad de entradas y de salidas\cite{nnwithJava} como punto de referencia para comenzar a evaluar los rendimientos de las arquitecturas.
	
	En el caso del conjunto de datos del problema 1, dado que hay 30 entradas y 1 salida evaluamos arquitecturas donde variamos las neuronas de la capa oculta en el conjunto ${5,10,15,20,25}$. 
	
	Para el problema 2, dado que hay 8 entradas y 2 salidas, evaluamos una capa oculta con cantidades en el conjunto ${2,4,6,8,10,12,14}$.
      
      
      \subsubsection{\'Epocas necesarias para obtener un buen resultados}
	Otro punto clave en el entrenamiento de la red es la cantidad de \'epocas a utilizar. Para evaluar este aspecto consideramos distintas cantidades para cada una de las arquitecturas mencionadas previamente.
	
	Para el problema 1, entrenamos usando 10, 20, 30, 40, 50, 60, 70, 80, 90, 100 \'epocas
      
      \subsubsection{Utilizaci\'on de distintos valores de learning rate}
      
      \subsubsection{Normalización de los datos}
      
      \subsubsection{Uso de momentum}
      
      
      
  
\end{document}