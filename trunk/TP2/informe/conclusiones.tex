\documentclass[informe.tex]{subfiles}
\begin{document}
  
  \section{Conclusiones}
  
  Considerando lo discutido en la sección de Resultados, haremos una breve recopilación de las conclusiones alcanzadas basadas en la experimentación realizada. 

    \subsection{Reducción de dimensiones}
      
      En relación a la ubicación espacial de las instancias al utilizar las tres primeras componentes principales calculadas, no se vieron malos resultados en el sentido de instancias totalmente dispersas o instancias de validación muy alejadas de las instancias de entrenamiento. En líneas generales, todas las instancias de experimentación analizadas presentaban características similares: algunas clases bien clusterizadas y otras tal vez menos concentradas espacialmente. Sin embargo, dado que con ninguno de los casos analizados se obtuvieron separaciones espaciales considerables entre todas las clases no podemos afirmar que alguna combinación de parámetros haya funcionado mejor. Para afirmar esto, dados los resultados obtenidos sería necesario realizar un posprocesamiento de los resultados, por ejemplo aplicar k vecinos más cercanos sobre las instancias de validación para ver si con la transformación obtenida a partir de las componentes principales calculadas se puede clasificar bien.
      
      ~
      
      Dado que los resultados espacialmente son similares haremos referencia a cu\'al m\'etodo resulta mejor en funci\'on de la cantidad de \'epocas que necesitan para alcanzar los resultados obtenidos. Dado que la combinación de ortogonalidad usando Oja converge en casi todos los casos analizados en una cantidad baja de épocas consideraremos que los mejores resultados fueron obtenidos con esta combinación. Sin embargo, queda pendiente analizar más en profundidad las características bajo las cuales la regla de Sanger converge dado que las veces que lo hizo, en general fue en menos épocas que Oja. Por otro lado, observando los resultados al usar el criterio de matriz de delta pesos nula es claro que con 500 y 250 \'epocas de máximo se alcanzó un nivel de convergencia con resultados espaciales similares. Por ende, sería necesario analizar a partir de qué época se alcanza esa convergencia. Por razones de tiempo planteamos ese análisis como trabajo futuro ya que implicaría realizar varias corridas sobre el set de datos para hallar el punto en el cual se empiezan a obtener los números observados para la norma Frobenius de la matriz de pesos. Otra posibilidad sería tratar de obtener la época en la cual se alcanza un valor similar, por ejemplo 0.005 aunque dependiendo del caso esto puede ser una aproximación burda.
      
      ~
      
      En relación a las preguntas planteadas en el enunciado se podría decir que dada la distribución espacial de las instancias no queda claro que se pueda hacer una clasificación precisa con todas las clases. Si bien algunas como las representadas con color azul y magenta aparecen normalmente más distanciadas de las demás y otras como las celeste y roja aparecen más concentradas, es posible que al aplicar un algoritmo de clasificación los resultados no sean muy buenos. Algo a tener en cuenta es que realizar clasificación apenas considerando 3 componentes principales sobre instancias con más de 800 parámetros parece demasiado ambicioso. Sería razonable analizar los resultados considerando más componentes principales y observar si all\'i se obtienen buenos resultados. Obviamente en esos casos no ser\'a posible hacer una representaci\'on visual como en este caso pero analizando, por ejemplo, knn sobre los vectores de la transformación se podr\'a observar si los resultados mejoran.
      
      En relación a la calidad de estos métodos para la clasificación de los documentos sería necesario analizarlos con una métrica cuantitativa (y no solamente basarnos en la apreciación cualitativa de los gráficos) sin embargo dada la poca diferenciación obtenida espacialmente pareciera que no son la mejor técnica a utilizar. Vale aclarar que la experimentación con las técnicas no fue exhaustiva y completa por cuestiones de tiempo por lo que aún quedan muchas posibilidades para explotar en los parámetros de los métodos.
      
      En cuanto a las mejoras o ampliaciones, algo a tener en cuenta es agregar un m\'etodo num\'erico para la clasificaci\'on de nuevas instancias dado el entrenamiento. Para ello se puede utilizar algoritmos como k-means y dadas esas implementaciones algo a tener en cuenta es analizar los resultados con más componentes principales. Otro aspecto a considerar es tratar de hallar un criterio adaptativo para el learning rate que permita converger más rápidamente ya que con los casos analizados no fue posible realizar este aprendizaje más rápidamente.
      
      
      
    \subsection{Mapeo de características}
    
    En general, se vieron resultados aceptables para todas las arquitecturas elegidas. La arquitectura que da resultados que no son tan aceptables es aquella más chica, de 5x5, ya que su factor de cruce es demasiado alto y por lo tanto puede que no dé una buena clasificaci\'on si se utiliza la red para ello. A partir de 10x10, el factor de cruce disminuye dr\'asticamente por lo que los resultados pasan a ser significativos.
    
    ~
    
    Creemos que una arquitectura de más de 30x30 es excesiva para este problema, ya que comienzan a verse demasiadas neuronas que no se activan para ninguna clase, lo que significa que la cantidad de neuronas puede reducirse para obtener resultados similares y as\'i disminuir el tiempo de entrenamiento.
  
    \subsection{Posibles trabajos futuros}
    
    En la reducción de dimensiones queda pendiente evaluar como criterio de corte para la matriz de delta pesos ver que dos matrices de épocas consecutivas sean prácticamente iguales ya que, como se vio en la experimentación, no se llega a que la matriz de delta pesos sea nula.
    
    ~
    
    En cuanto al mapeo de características, quedan muchas experimentaciones por las cuales seguir investigando. Por ejemplo, experimentar con par\'ametros fijos ya que solamente lo hicimos con auto-ajustables, con distintas funciones de distancia y actualizaci\'on, con arquitecturas no cuadradas de neuronas; con una arquitectura de salida distinta, con tal de lograr un clasificador y con ello verificar precisi\'on, etc. Otra línea interesante a investigar es la posibilidad de efectuar una reducción de dimensionalidad antes de entrenar la red para realizar la clusterizaci\'on en un espacio que tenga menos dimensiones, y que por lo tanto lleve menos tiempo, verificando que la proyecci\'on del conjunto de entrenamiento en el subespacio nuevo no altera los resultados de la red neuronal.
    
\end{document}